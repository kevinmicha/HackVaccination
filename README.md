# VaxLens: Data-Driven Vaccine Insights

[![Python 3.8 - 3.11](https://img.shields.io/badge/Python-3.8%20--%203.11-blue)](https://www.python.org/downloads/release/python-3113/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green)](https://opensource.org/license/mit/)

Vaccine hesitancy is often fueled by misinformation propagated on social media platforms such as Twitter, Bluesky, and TikTok. This phenomenon affects diverse age groups and regions in varying ways, making it a multifaceted challenge. To address this issue, we propose a solution that enables Medical Affairs teams to intervene effectively and reduce reluctance toward vaccination.

Our approach involves leveraging Bluesky for data collection. We chose Bluesky because its platform allows easier scraping without requiring a lengthy developer signup process. The scraping functionality is implemented in the tweet_processing.py script, which dynamically retrieves the latest posts, including their text, reactions (likes, responses, and comments), timestamps, and location metadata.

As we expand this project, we aim to enhance our data collection by including posts in multiple languages. This will help us explore how misinformation spreads across linguistic and cultural boundaries. Additionally, we plan to gather more user-specific details, such as follower counts and demographic information, to better understand the influence and reach of individual users spreading misinformation.

## Data Processing and Analysis

Once raw data is collected, we preprocess it using a Large Language Model (LLM). The LLM performs several key tasks:

* **Sentiment analysis:** classifies posts as positive, negative, or neutral.
* **Keyword extraction:** summarises each post with three key terms.
* **Demographic estimation:** estimates the gender and age group of the user.

Initially, we considered using Fetch.AI agents for processing. However, due to the high volume of real-time posts, the Fetch.AI query limits were quickly exceeded. To address this, we opted for an alternative agent that can handle the scale of data more efficiently.

## Generating Insights and Interventions

Using the processed data, we compute actionable statistics to guide Medical Affairs interventions. Here’s how our system works, all of it is using agents from FetchAI.

* **Dynamic triggering:** every fixed amount of time, our agent analyses the latest processed data, identifying trends and generating prompts based on negative posts.
* **Validation:** these prompts undergo additional sentiment analysis to confirm their negative tone using a sentiment analysis agent.
* **Counter-misinformation research:** a trusted-source scraping agent (Tabily) identifies credible information to address the misinformation in the flagged posts.
* **Response creation:** an OpenAI agent generates draft posts for Medical Affairs to review and potentially publish, ensuring timely and effective communication.
* **Image generation:** finally an Image generator agent creates an image to go with the post that we have created.

## Interactive dashboard

The repository also features a Streamlit app that provides an interactive dashboard to visualise and manage the insights generated by the system. The main page of the dashboard includes:

* **Time-series evolution:** tracks the trends of positive and negative posts over time.
* **Evolving word cloud:** displays key keywords weighted by importance and their evolution across time.
* **Geographic insights:** maps the distribution of posts by geographic area.
* **Generated posts:** lists posts created by the system, allowing users to click on each for detailed insights.

Clicking on a previously generated post opens a new tab that provides:

* The original flagged post and the trusted sources used to counter misinformation.
* The evolution of positive and negative posts following our intervention.
* Reactions to the post, segmented by filters such as location, age group, or sentiment.
* Alert System for Real-Time Response
* The dashboard also includes an alert feature based on time-series trends. 

When an alert is triggered, a new tab is opened to display:

* The event or trend that activated the alert.
* A proposed response post created by the system's agents.
* A button to review and publish the suggested post.
* This dashboard streamlines real-time monitoring and facilitates rapid, informed interventions by Medical Affairs teams.

### Manually handling the dependencies

If you want to use an existing environment, just omit the Anaconda commands above:
```bash
git clone https://github.com/kevinmicha/HackVaccination
cd HackVaccination
pip install .
```

or if you need to install it for your user only: 
```bash
python setup.py install --user 
```

## Requirements 

This project requires the following Python packages: 
* `uagents`
* `asyncio`
* `threading`
* `selenium`
* `webdriver_manager`
* `datetime`
* `csv`


## **Usage**

Follow these steps to use VaxLens effectively:

1. **Process tweets**  
   Run the `tweet_processing.py` script to collect and preprocess vaccine-related tweets. This script fetches tweets using the Twitter API and saves them in a CSV format for further processing.

   ```bash
   python tweet_processing.py
   ```

   **Output**:  
   A CSV file containing raw vaccine-related tweets, including metadata such as user information and tweet engagement metrics.

2. **Sentiment analysis and keyword extraction**  
   Run the `LLM_agent.py` script to analyse the tweets. This script:
   - Classifies tweets as **POSITIVE**, **NEUTRAL**, or **NEGATIVE** using sentiment analysis.
   - Extracts **keywords** from tweets to identify trends and problematic topics.
   - Estimates the **age demographic** of users posting the tweets.

   ```bash
   python LLM_agent.py
   ```

   **Output**:  
   The updated CSV file will include new columns for:
   - **Sentiment**: Classification of the tweet’s tone.
   - **Keywords**: Highlighted key terms for targeted responses.
   - **Age Estimation**: Approximation of user age for demographic insights.

3. **Agent responses**  
   Run the `advanced_code.py` script to perform the following actions with `uAgents`:
   - Analyse extracted keywords to identify problematic narratives.
   - Use agents to search the web for context and reliable sources.
   - Propose AI-generated fact-based and empathetic responses.

   ```bash
   python advanced_code.py
   ```

4. **Visualise insights**  
   Launch the Streamlit dashboard to visualise flagged tweets, analyse trends, and review suggested responses.

   ```bash
   streamlit run tweet_dashboard.py
   ```


## **Contributing**

We welcome contributions! Feel free to submit pull requests or open issues for any improvements or bug fixes.


## **License**

This project is licensed under the [MIT License](https://opensource.org/license/mit/).
